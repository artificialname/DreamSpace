import os
import gradio as gr
from transformers import pipeline

# Load GPT-2 for text generation
try:
    generator = pipeline("text-generation", model="gpt2")
except Exception as e:
    raise RuntimeError("Failed to load the GPT-2 model. Ensure Transformers library is installed and the model is accessible.") from e

# Define the text generation function
def generate_text(prompt):
    try:
        if not prompt:
            return "Please provide a prompt."
        result = generator(prompt, max_length=50, num_return_sequences=1)
        return result[0]['generated_text']
    except Exception as e:
        return f"An error occurred: {str(e)}"

# Create the Gradio interface
iface = gr.Interface(
    fn=generate_text,
    inputs=gr.Textbox(label="Prompt", lines=2),
    outputs="text",
    title="Text Generation with GPT-2",
    description="Provide a prompt and get text generated by GPT-2."
)

# Launch the Gradio app with the correct port for Render
port = int(os.environ.get("PORT", 10000))  # Use Render's PORT or default to 10000
print(f"Server running on port {port}")  # Log the port number to help with debugging
iface.launch(
    server_name="0.0.0.0",  # Listen on all network interfaces
    server_port=port        # Use the dynamic port assigned by Render
)
